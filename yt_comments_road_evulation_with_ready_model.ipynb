{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract youtube video id form link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "API_KEY = \"\"\n",
    "VIDEO_ID = \"\"\n",
    "VIDEO_LINK = \"https://youtu.be/-RJ0xGYUHBE?si=pPHpGjkauo_e6m68\"\n",
    "def extract_video_id(url):\n",
    "    regex = r'(?:https?://)?(?:www\\.)?(?:youtube\\.com/(?:watch\\?v=|shorts/)|youtu\\.be/)([a-zA-Z0-9_-]{11})'\n",
    "\n",
    "    match = re.match(regex, url)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1) \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "VIDEO_ID = extract_video_id(VIDEO_LINK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets all comments in video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. page processed. Total comments: 214\n",
      "2. page processed. Total comments: 294\n",
      "\n",
      " A total of 294 comments withdrawn.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "comments = []\n",
    "next_page_token = None\n",
    "page_count = 0\n",
    "\n",
    "while True:\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet,replies&videoId={VIDEO_ID}&maxResults=100&key={API_KEY}\"\n",
    "    if next_page_token:\n",
    "        url += f\"&pageToken={next_page_token}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error code: {response.status_code}\")\n",
    "        print(response.json())\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    page_count += 1\n",
    "\n",
    "    for item in data.get(\"items\", []):\n",
    "        top_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "        comments.append(top_comment)\n",
    "\n",
    "        replies = item.get(\"replies\", {}).get(\"comments\", [])\n",
    "        for reply in replies:\n",
    "            reply_text = reply[\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(reply_text)\n",
    "\n",
    "    print(f\"{page_count}. page processed. Total comments: {len(comments)}\")\n",
    "\n",
    "    next_page_token = data.get(\"nextPageToken\")\n",
    "    if not next_page_token:\n",
    "        break\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n A total of {len(comments)} comments withdrawn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We make comments clean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matter anyone say neither hurrem anyone family brought death prince mustafa janissary brought mustafa death say turk government accept shadow suleyman afraid blow would come son blow father made father', 'href www youtube com watch v rj xgyuhbe amp iklim k tan n sultan', 'quot never dare quot used phrase many time br janissary honor liar coward', 'insan kafas de il de sanki r ko kesiyor herif kar ndaki adam profesyonel komutan adam n eli armut mu topluyor lan cellatl k kurumu niye var acaba', 'suleyman mannificient could leave capable heir killed capable one left great empire imbecile']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from contractions import fix\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        text = fix(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Contraction error: {e} | Original text: {text}\")\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "cleaned_comments = [clean_text(comment) for comment in comments]\n",
    "\n",
    "print(cleaned_comments[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We predict negative comments  according with ready trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments detected 16 unit.\n",
      "['selim alone reason ottoman lost central europe way complicated first took year suleiman lost central europe give selim much credit fall empire guy ruled year way quot begining end quot empire actually quite stable thanks pasha rule even actually got minor teritory gain br multiple factor played role fall ottoman empire br th century spain begin got shitload gold america starting inflation ottoman empire nothing america br starting reign murad huge amount coruption started within ottoman empire play huge role fall empire br coruption started army within next generation gained extreme amount power influence even year suleiman died killed sultan osman br br shortly said murad spain infuence fall empire selim murad decent sultan could easily continue suleimans work acting selims rule minor set back mehmed decent sultan would still take year trying fix problem murad caused could even think expanding', 'sultan suleyman cut janissary agha head shehzade prince mustafa sword close relationship janissary reason bad look placing back sword sheath', 'saying also message mustofa mustofa never needed kind message mustofa always obliged father mustofa saved selim give farhat aga strong message mustofa suleiman ill empire would face bad time', 'barbarian nothing else ottoman', 'kill janisarries killed irregular want join modern army even commander chef modern army ex janissary officer reform must done janisarries poor aganist european army indomitable defender status quo']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "rf = joblib.load(\"trained_sentiment.pkl\")\n",
    "vectorizer = joblib.load(\"sentiment_vectorizer.pkl\")\n",
    "\n",
    "transformed_comments = vectorizer.transform(cleaned_comments).toarray()\n",
    "\n",
    "predictions = rf.predict(transformed_comments)\n",
    "\n",
    "bad_comment_list = [cleaned_comments[i] for i in range(len(predictions)) if predictions[i] == 0]\n",
    "\n",
    "print(f\"Negative comments detected {len(bad_comment_list)} unit.\")\n",
    "print(bad_comment_list[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = \"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get suggestion in ai model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Casper\\Desktop\\Projects\\CommentEvuluation\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Casper\\Desktop\\Projects\\CommentEvuluation\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "Comments to send for the cluster 0:\n",
      "- selim alone reason ottoman lost central europe way complicated first took year suleiman lost central europe give selim much credit fall empire guy ruled year way quot begining end quot empire actually quite stable thanks pasha rule even actually got minor teritory gain br multiple factor played role fall ottoman empire br th century spain begin got shitload gold america starting inflation ottoman empire nothing america br starting reign murad huge amount coruption started within ottoman empire play huge role fall empire br coruption started army within next generation gained extreme amount power influence even year suleiman died killed sultan osman br br shortly said murad spain infuence fall empire selim murad decent sultan could easily continue suleimans work acting selims rule minor set back mehmed decent sultan would still take year trying fix problem murad caused could even think expanding\n",
      "- sultan osman han like none happened would happened needed show jenessaries place let know major sin islam disobey ruler whether unjust taken head could anything also trusted kosem sultan beginning none would happened\n",
      "- sultan suleyman cut janissary agha head shehzade prince mustafa sword close relationship janissary reason bad look placing back sword sheath\n",
      "\n",
      "Comments to send for the cluster 1:\n",
      "- fake stupid real history right\n",
      "- read real history sister one powerful ruler world one best lawgiver spent year reign battlefield saying suck gt serial nothing fake fiction producer accepted reality serial\n",
      "\n",
      "ğŸ“Œ Cluster 0 Final Summary:\n",
      "Okay, here's a summary of the user comments:\n",
      "\n",
      "**Common Complaints/Issues:**\n",
      "\n",
      "*   **Oversimplification of Ottoman Decline:** Users criticize attributing the Ottoman Empire's decline solely to Selim. They emphasize that it was a complex process influenced by numerous factors.\n",
      "*   **Economic Issues:** Mention of Spanish gold from the Americas causing inflation in the Ottoman Empire.\n",
      "*   **Corruption and Janissary Power:** Highlighted corruption starting with Murad and the growing power and influence of the Janissaries as major factors.\n",
      "*   **Sultan Osman's Mistakes:** Criticisms of Osman's handling of the Janissaries and the negative influence of Kosem Sultan.\n",
      "*   **Suleyman's Actions & Janissaries:** Criticisms of Suleyman's relationship with Janissaries.\n",
      "\n",
      "**Roadmap for Future Discussion:**\n",
      "\n",
      "To address the users' concerns in the future, focus on these areas:\n",
      "\n",
      "1.  **Complexity of Ottoman History:** Avoid oversimplified explanations. Emphasize that multiple factors contributed to the Ottoman Empire's rise and decline.\n",
      "2.  **Economic Analysis:** Include a discussion of economic factors like inflation caused by Spanish gold and its impact on the Ottoman economy.\n",
      "3.  **Internal Power Struggles:** Explore the internal dynamics of the Ottoman court, including corruption, Janissary power, and the influence of figures like Kosem Sultan.\n",
      "4.  **Nuanced Ruler Assessments:** Avoid simple \"good\" or \"bad\" labels for Sultans. Analyze their actions in context and acknowledge both successes and failures.\n",
      "5.  **Janissaries Role:** Address in depth the role of Janissaries in both contributing to Ottoman power and the subsequent internal conflict that led to weakening of the empire.\n",
      "\n",
      "By addressing these points, future discussions will be more comprehensive and address the users' specific concerns about accuracy and depth.\n",
      "\n",
      "\n",
      "\n",
      "ğŸ“Œ Cluster 1 Final Summary:\n",
      "**Summary of User Comments:**\n",
      "\n",
      "The user believes the historical drama/serial is inaccurate and fabricated. They emphasize the importance of \"real history\" and claim the depiction of the ruler is unrealistic, focusing on battlefields and vulgar language.\n",
      "\n",
      "**Common Complaints/Issues:**\n",
      "\n",
      "*   **Historical Inaccuracy:** The primary complaint is that the drama deviates from \"real history\" and presents a false portrayal of events and characters.\n",
      "*   **Character Portrayal:** The user objects to the depiction of a powerful ruler as someone constantly on the battlefield and using vulgar language (\"suck gt serial\").\n",
      "*   **Lack of Authenticity:** The user perceives the show as \"fake\" and \"fiction,\" suggesting a lack of realism and fidelity to historical sources.\n",
      "\n",
      "**Roadmap for Future Focus:**\n",
      "\n",
      "1.  **Prioritize Historical Accuracy:**\n",
      "    *   Consult with historical experts during the writing and production phases.\n",
      "    *   Clearly define any artistic liberties taken and their rationale.\n",
      "    *   Provide disclaimers or explanations about the historical context and deviations.\n",
      "\n",
      "2.  **Ensure Believable Character Portrayals:**\n",
      "    *   Develop well-rounded characters with motivations grounded in historical context.\n",
      "    *   Avoid excessive or anachronistic dialogue and behaviors.\n",
      "    *   Show, don't just tell, how the ruler achieved power and maintained control.\n",
      "\n",
      "3.  **Strive for Authenticity:**\n",
      "    *   Pay attention to details in set design, costumes, and language to reflect the time period.\n",
      "    *   Conduct thorough research on the culture, customs, and daily life of the era.\n",
      "    *   Avoid modern sensibilities or values that clash with the historical setting.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def generate_summary_with_gemini(comments, apiKey):\n",
    "    prompt = f\"\"\"Summarize user comments below. What are the common complaints or issues? And can you draw a Roadmap for what to pay more attention to next time? Briefly and clearly\n",
    "\n",
    "Comments:\n",
    "{chr(10).join(f\"- {comment}\" for comment in comments)}\n",
    "\"\"\"\n",
    "    data = {\n",
    "        \"contents\": [ { \"parts\": [ { \"text\": prompt } ] } ]\n",
    "    }\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={apiKey}\"\n",
    "    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=data)\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        if 'candidates' in response_data:\n",
    "            return response_data['candidates'][0].get('content', {}).get('parts', [{}])[0].get('text', None)\n",
    "    else:\n",
    "        print(f\"API error: {response.status_code}\")\n",
    "    return None\n",
    "\n",
    "def get_representative_comments(comments, model, top_n=3):\n",
    "    embeddings = model.encode(comments)\n",
    "    centroid = np.mean(embeddings, axis=0)\n",
    "    distances = np.linalg.norm(embeddings - centroid, axis=1)\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    return [comments[i] for i in sorted_indices[:top_n]]\n",
    "\n",
    "def optimal_k_means(X, max_k=30):\n",
    "    best_score = -1\n",
    "    best_k = 2\n",
    "    for k in range(2, min(max_k, len(X)) + 1):\n",
    "        kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42).fit(X)\n",
    "        score = silhouette_score(X, kmeans.labels_)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    return best_k\n",
    "\n",
    "def determine_max_k(n_comments):\n",
    "    if n_comments < 10:\n",
    "        return 1 \n",
    "    elif n_comments < 20:\n",
    "        return 2\n",
    "    elif n_comments < 30:\n",
    "        return 3\n",
    "    elif n_comments < 50:\n",
    "        return 4\n",
    "    elif n_comments < 200:\n",
    "        return 8\n",
    "    elif n_comments < 500:\n",
    "        return 12\n",
    "    elif n_comments < 1000:\n",
    "        return 20\n",
    "    return 30\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "comment_embeddings = model.encode(bad_comment_list)\n",
    "\n",
    "max_clusters = determine_max_k(len(bad_comment_list))\n",
    "num_clusters = max(1, optimal_k_means(comment_embeddings, max_k=max_clusters))\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "clusters = kmeans.fit_predict(comment_embeddings)\n",
    "\n",
    "grouped_comments = {}\n",
    "for idx, cluster_id in enumerate(clusters):\n",
    "    grouped_comments.setdefault(cluster_id, []).append(bad_comment_list[idx])\n",
    "\n",
    "summaries = {}\n",
    "for cluster_id, comments in grouped_comments.items():\n",
    "    reps = get_representative_comments(comments, model, top_n=3) \n",
    "    print(f\"\\nComments to send for the cluster {cluster_id}:\")\n",
    "    for r in reps:\n",
    "        print(f\"- {r}\")\n",
    "    summary = generate_summary_with_gemini(reps, apiKey)\n",
    "    summaries[cluster_id] = summary\n",
    "\n",
    "for cluster_id, summary in summaries.items():\n",
    "    print(f\"\\nğŸ“Œ Cluster {cluster_id} Final Summary:\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
