{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract youtube video id form link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "API_KEY = \"\"\n",
    "VIDEO_ID = \"\"\n",
    "VIDEO_LINK = \"https://youtu.be/-RJ0xGYUHBE?si=pPHpGjkauo_e6m68\"\n",
    "def extract_video_id(url):\n",
    "    regex = r'(?:https?://)?(?:www\\.)?(?:youtube\\.com/(?:watch\\?v=|shorts/)|youtu\\.be/)([a-zA-Z0-9_-]{11})'\n",
    "    match = re.match(regex, url)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "VIDEO_ID = extract_video_id(VIDEO_LINK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gets all comments in video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. page processed. Total comments: 214\n",
      "2. page processed. Total comments: 294\n",
      "\n",
      " A total of 294 comments withdrawn.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "comments = []\n",
    "next_page_token = None\n",
    "page_count = 0\n",
    "\n",
    "while True:\n",
    "    url = f\"https://www.googleapis.com/youtube/v3/commentThreads?part=snippet,replies&videoId={VIDEO_ID}&maxResults=100&key={API_KEY}\"\n",
    "    if next_page_token:\n",
    "        url += f\"&pageToken={next_page_token}\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error code: {response.status_code}\")\n",
    "        print(response.json())\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    page_count += 1\n",
    "\n",
    "    for item in data.get(\"items\", []):\n",
    "        top_comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "        comments.append(top_comment)\n",
    "\n",
    "        replies = item.get(\"replies\", {}).get(\"comments\", [])\n",
    "        for reply in replies:\n",
    "            reply_text = reply[\"snippet\"][\"textDisplay\"]\n",
    "            comments.append(reply_text)\n",
    "\n",
    "    print(f\"{page_count}. page processed. Total comments: {len(comments)}\")\n",
    "\n",
    "    next_page_token = data.get(\"nextPageToken\")\n",
    "    if not next_page_token:\n",
    "        break\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n A total of {len(comments)} comments withdrawn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download is successful\n"
     ]
    }
   ],
   "source": [
    "from turkishnlp import detector as tr_detector \n",
    "\n",
    "tr_lemmatizer = tr_detector.TurkishNLP()\n",
    "tr_lemmatizer.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we make comments clean according to english or turkish comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matter anyone say neither hurrem anyone family brought death prince mustafa janissary brought mustafa death say turk government accept shadow suleyman afraid blow would come son blow father made father', 'a href iklim kıtanın sultanı', 'quot never dare quot used phrase many time br janissary honor liar coward', 'insan kafası değil mısır koçanı kesiyor herif karşısındaki adam profesyonel komutan adamın eli armut topluyor lan cellatlık kurumu var', 'suleyman mannificient could leave capable heir killed capable one left great empire imbecile']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import langid\n",
    "\n",
    "def clean_text_multilingual(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text.replace(\" \", \"\"))\n",
    "\n",
    "    if word_count < 2 and char_count < 5: # ???\n",
    "        return \"\"\n",
    "\n",
    "    lang, _ = langid.classify(text)\n",
    "\n",
    "    text = re.sub(r'http\\S+', '', text) \n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = text.lower().strip()\n",
    "\n",
    "    if lang == \"tr\":\n",
    "        text = re.sub(r'[^\\wçğıöşüÇĞİÖŞÜ ]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        stop_words = set(get_stop_words('turkish'))\n",
    "        tokens = tr_lemmatizer.list_words(text)\n",
    "        cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    else:  \n",
    "        text = re.sub(r'[^\\w]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        stop_words = set(nltk_stopwords.words('english'))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = text.split()\n",
    "        cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "cleaned_comments = [clean_text_multilingual(comment) for comment in comments]\n",
    "\n",
    "print(cleaned_comments[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we extract negative comments according to language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Casper\\Desktop\\Projects\\CommentEvuluation\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Casper\\Desktop\\Projects\\CommentEvuluation\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments detected (103 unit):\n",
      "(1, 'matter anyone say neither hurrem anyone family brought death prince mustafa janissary brought mustafa death say turk government accept shadow suleyman afraid blow would come son blow father made father')\n",
      "(2, 'quot never dare quot used phrase many time br janissary honor liar coward')\n",
      "(3, 'suleyman mannificient could leave capable heir killed capable one left great empire imbecile')\n",
      "(4, 'true blinded deep love ruthenian girl hurrem imbecile died falling ground trying cath concubine running bath')\n",
      "(5, 'even today people mourns prince mustafa death sultan ottoman great field marshall mustafa par sultan however selim lack capability started downfall ottoman empire')\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import langid \n",
    "import re\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        lang, confidence = langid.classify(text)\n",
    "        return 'tr' if lang == 'tr' else 'en' if lang == 'en' else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "MODELS = {\n",
    "    \"en\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    \"tr\": \"savasy/bert-base-turkish-sentiment-cased\" \n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    \"en\": pipeline(\"sentiment-analysis\", model=MODELS[\"en\"]),\n",
    "    \"tr\": pipeline(\"sentiment-analysis\", model=MODELS[\"tr\"])\n",
    "}\n",
    "\n",
    "def analyze_sentiment(comment):\n",
    "    lang = detect_language(comment)\n",
    "    if not lang:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        result = pipelines[lang](comment)[0]\n",
    "        label = result[\"label\"].upper()\n",
    "        score = result[\"score\"]\n",
    "        \n",
    "        if lang == \"tr\":\n",
    "            label = \"NEGATIVE\" if label == \"LABEL_0\" else \"POSITIVE\"\n",
    "            \n",
    "        return {\"label\": label, \"score\": score}\n",
    "    except Exception as e:\n",
    "        print(f\"Analysis error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "bad_comments = []\n",
    "\n",
    "for comment in cleaned_comments:\n",
    "    analysis = analyze_sentiment(comment)\n",
    "    if analysis and analysis[\"label\"] == \"NEGATIVE\" and analysis[\"score\"] > 0.80:\n",
    "        bad_comments.append(comment)\n",
    "\n",
    "print(f\"Negative comments detected ({len(bad_comments)} unit):\")\n",
    "for com in enumerate(bad_comments[0:5], 1):\n",
    "    print(com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get suggestion in ai model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comments to send for the cluster 1:\n",
      "- second time chop head janissary high command young phrase say quot younger self br br first one br href artist halit ergenc played magnificently sceenes nervous first janissary revolt confident middle janissary barrack one year rulled\n",
      "- comment show ur understanding history zero middle age ended renaissance era selim fault tried control janisarries suleiman got sick got mad one listen know cause he fkingg drunk\n",
      "- sultan osman han like none happened would happened needed show jenessaries place let know major sin islam disobey ruler whether unjust taken head could anything also trusted kosem sultan beginning none would happened\n",
      "\n",
      "Comments to send for the cluster 0:\n",
      "- ottoman sultan took white kid knew white bitter warrior like arab mamluks mainly white kid russian georgian greek armenian christian\n",
      "- ultimate subjugator greek balkan mideast shall bow turk ccc\n",
      "- problem crimean khanate many khazar turk jew region later destroyed ottoman empire founded turkey\n",
      "\n",
      "📌 Cluster 1 Final Summary:\n",
      "**Summary of Comments:**\n",
      "\n",
      "*   **Praise:** Halit Ergenc's acting performance is highlighted.\n",
      "*   **Criticism:** Historical accuracy is questioned, particularly regarding Selim's actions and the role of the Janissaries. Sultan Osman's approach to the Janissaries is debated.\n",
      "\n",
      "**Common Complaints/Issues:**\n",
      "\n",
      "*   **Historical Inaccuracies:** Discrepancies between the show's portrayal and perceived historical events/figures.\n",
      "*   **Character Actions/Motivations:** Disagreement with how certain characters (Selim, Osman) are depicted and their choices.\n",
      "\n",
      "**Roadmap for Next Time (Addressing Concerns):**\n",
      "\n",
      "1.  **Historical Context Consultation:** Ensure thorough consultation with historians for accuracy, particularly regarding sensitive events and character portrayals.\n",
      "2.  **Character Motivation Justification:** Clearly establish and justify character motivations through dialogue, narration, or flashbacks, especially when deviating from common historical interpretations.\n",
      "3.  **Balanced Perspective:** Acknowledge and portray different perspectives on historical events within the show to create nuance.\n",
      "\n",
      "\n",
      "\n",
      "📌 Cluster 0 Final Summary:\n",
      "**Summary of Comments:**\n",
      "\n",
      "The comments express opinions about historical topics, specifically:\n",
      "\n",
      "*   The Ottoman Empire and its use of white (likely Christian) soldiers/slaves, similar to the Mamluk system.\n",
      "*   Claims of Ottoman/Turkish domination and subjugation of the Balkans, Middle East, and Greece.\n",
      "*   References to the Crimean Khanate, Khazars, and a connection to the later Ottoman Empire and modern Turkey, seemingly linking them to Jewish origins or influence and crime.\n",
      "\n",
      "**Common Complaints/Issues:**\n",
      "\n",
      "*   Historical revisionism: The comments present a biased and potentially inaccurate view of historical events.\n",
      "*   Religious/ethnic bias: There are undertones of anti-Turkish, anti-Semitic, and potentially anti-Christian sentiment.\n",
      "*   Promotion of hate: The language used is inflammatory and aimed at inciting negative feelings towards specific groups.\n",
      "\n",
      "**Roadmap for Future Attention:**\n",
      "\n",
      "1.  **Moderate Biased historical claims**: Remove content that promotes historical revisionism.\n",
      "2.  **Moderate/Remove Discriminatory remarks**: Immediately remove any comments displaying hate speech, ethnic slurs, or religious prejudice.\n",
      "3.  **Contextual analysis**: understand the historical context to remove hate claims.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def generate_summary_with_gemini(comments, apiKey):\n",
    "    prompt = f\"\"\"Summarize user comments below. What are the common complaints or issues? And can you draw a Roadmap for what to pay more attention to next time? Briefly and clearly\n",
    "\n",
    "    Comments:\n",
    "    {chr(10).join(f\"- {comment}\" for comment in comments)}\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"contents\": [ { \"parts\": [ { \"text\": prompt } ] } ]\n",
    "    }\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={apiKey}\"\n",
    "    response = requests.post(url, headers={'Content-Type': 'application/json'}, json=data)\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        if 'candidates' in response_data:\n",
    "            return response_data['candidates'][0].get('content', {}).get('parts', [{}])[0].get('text', None)\n",
    "    else:\n",
    "        print(f\"API hatası: {response.status_code}\")\n",
    "    return None\n",
    "\n",
    "def get_representative_comments(comments, model, top_n=3): \n",
    "    embeddings = model.encode(comments) \n",
    "    centroid = np.mean(embeddings, axis=0) \n",
    "    distances = np.linalg.norm(embeddings - centroid, axis=1) \n",
    "    sorted_indices = np.argsort(distances) \n",
    "    return [comments[i] for i in sorted_indices[:top_n]]\n",
    "\n",
    "def optimal_k_means(X, max_k=30):\n",
    "    best_score = -1\n",
    "    best_k = 2\n",
    "    for k in range(2, min(max_k, len(X)) + 1):  \n",
    "        kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42).fit(X)\n",
    "        score = silhouette_score(X, kmeans.labels_) \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    return best_k\n",
    "\n",
    "def determine_max_k(n_comments):\n",
    "    if n_comments < 10:\n",
    "        return 1 \n",
    "    elif n_comments < 20:\n",
    "        return 2\n",
    "    elif n_comments < 35:\n",
    "        return 3\n",
    "    elif n_comments < 50:\n",
    "        return 4\n",
    "    elif n_comments < 200:\n",
    "        return 8\n",
    "    elif n_comments < 500:\n",
    "        return 12\n",
    "    elif n_comments < 1000:\n",
    "        return 20\n",
    "    return 30\n",
    "\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2') \n",
    "comment_embeddings = model.encode(bad_comments)\n",
    "\n",
    "max_clusters = determine_max_k(len(bad_comments)) \n",
    "num_clusters = max(1, optimal_k_means(comment_embeddings, max_k=max_clusters)) \n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "clusters = kmeans.fit_predict(comment_embeddings)\n",
    "\n",
    "grouped_comments = {} \n",
    "for idx, cluster_id in enumerate(clusters):\n",
    "    grouped_comments.setdefault(cluster_id, []).append(bad_comments[idx])\n",
    "\n",
    "summaries = {}\n",
    "for cluster_id, comments in grouped_comments.items():\n",
    "    reps = get_representative_comments(comments, model, top_n=3) \n",
    "    print(f\"\\nComments to send for the cluster {cluster_id}:\")\n",
    "    for r in reps:\n",
    "        print(f\"- {r}\")\n",
    "    summary = generate_summary_with_gemini(reps, apiKey) \n",
    "    summaries[cluster_id] = summary\n",
    "\n",
    "for cluster_id, summary in summaries.items():\n",
    "    print(f\"\\n📌 Cluster {cluster_id} Final Summary:\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
